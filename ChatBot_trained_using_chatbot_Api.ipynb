{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChRvpqnLGkVV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "1b9332df-6f21-4f8c-f934-58d003abd2da"
      },
      "source": [
        "%pip install tensorflow-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/93/c7bca39b23aae45cd2e85ad3871c81eccc63b9c5276e926511e2e5b0879d/tensorflow_gpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.34.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 26.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 26.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu) (46.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.2.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.21.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.7.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.0)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow-addons~=0.7.0, but you'll have tensorflow-addons 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed tensorboard-2.1.1 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2g8TXZlHdkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhIL9SnrHnaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_data=tf.keras.utils.get_file('file','https://raw.githubusercontent.com/projjal1/datasets/master/master_chat_bot_data.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZda1ddTHtwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=open(file_data,'r').readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aIdAznIHxjU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1f3a691a-bf2e-48c1-fe48-ae789bd2a89d"
      },
      "source": [
        "print(text[:220])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Human 1: Hi!\\n', 'Human 2: What is your favorite holiday?\\n', 'Human 1: one where I get to meet lots of different people.\\n', 'Human 2: What was the most number of people you have ever met during a holiday?\\n', 'Human 1: Hard to keep a count. Maybe 25.\\n', 'Human 2: Which holiday was that?\\n', 'Human 1: I think it was Australia\\n', 'Human 2: Do you still talk to the people you met?\\n', \"Human 1: Not really. The interactions are usually short-lived but it's fascinating to learn where people are coming from and what matters to them\\n\", 'Human 2: Yea, me too. I feel like God often puts strangers in front of you, and gives you an opportunity to connect with them in that moment in deeply meaningful ways. Do you ever feel like you know things about strangers without them telling you?\\n', 'Human 1: what do you mean?\\n', 'Human 2: I think it\\'s like a 6th sense, often seen as \"cold readings\" to people, but can be remarkably accurate. I once sat next to a man in a coffee and I felt a pain in my back. I asked the stranger if he had a pain. It turns out that he did in the exact spot, and said he pulled a muscle while dancing at a party. I had never met the man before and never saw him again.\\n', \"Human 1: Wow! That's interesting, borderline spooky\\n\", 'Human 2: There\\'s this practice called \"Treasure Hunting\" that\\'s kind of a fun game you play in a public place. There\\'s a book called \"The Ultimate Treasure Hunt\" that talks about it. You use your creativity to imagine people you will meet, and you write down a description, then you associate them with a positive message or encouraging word. Maybe you saw a teenage boy in a red hat at the shopping mall in your imagination, then while at the mall, you may find someone who matches that description. You show that you have a message for him and that you have a message for a boy in a red hat. You then give him a message of kindness or whatever was on your heart. You have no idea, sometimes you meet someone who is having a really hard day, and it brings them to tears to have a stranger show them love.\\n', 'Human 1: So, do you do treasure hunting often?\\n', \"Human 2: I did more when I was in grad school (and had more time). I would usually go with friends. For a while I would go to the farmers market in Santa Cruz every week and try to feel if there is something I am supposed to tell a stranger. Usually, they are vague hope-filled messages, but it's weird when I blurt out something oddly specific.\\n\", 'Human 1: Hi\\n', 'Human 2: Any plans for the weekend?\\n', 'Human 1: my friends are gonna visit me this weekend. we might go hiking!\\n', \"Human 2: That's great! How's the weather over the weekend? I hope its warm.\\n\", 'Human 1: Should be very sunny! you?\\n', 'Human 2: Cool! very depressing plans ... stay home and work 😞 I have a project deadline very close.\\n', 'Human 1: 😐 hope you get your work done very soon! a bug free weekend!\\n', 'Human 2: Right, very anxious! where do you plan to go for a hike?\\n', 'Human 1: I am going to Diablo!\\n', \"Human 2: Nice, where is that place? I haven't been there\\n\", 'Human 1: hours drive from here. still in bay area\\n', \"Human 2: That's cool! How long is the hike?\\n\", 'Human 1:  Actually no idea, but it will take the entire day for that.\\n', 'Human 2: nice! sounds fun!\\n', 'Human 1: Hi!\\n', \"Human 2: Hey there! What's up???\\n\", 'Human 1: Nothing much, how you doin?\\n', \"Human 2: I'm in New York this week for Thanksgiving. I'm squatting in the office today and I caught up with an old friend of mine :D\\n\", 'Human 1: Oh wow! Sounds like fun! When was the last time you had seen this friend?\\n', 'Human 2: The last time in New York, back in June.\\n', \"Human 1: Ohh okay. I was going to say if it had been a long time maybe it'd be awkward...\\n\", \"Human 2: Haha, I guess if it's been a very long time there's almost too many life events to catch up on.. especially recently\\n\", 'Human 1: Oh really? Has a lot changed in your life recently?\\n', \"Human 2: Haha it's probably too much to go into at the moment. Let's just say life is an exciting experience. How about you?\\n\", 'Human 1: Ahhh sounds exciting indeed! My life is pretty bland. I like routine, but sometimes I wish I had more time for adventures!\\n', 'Human 2: What kinds of adventures?? Any ones that I would be able to join you on?\\n', 'Human 1: Hmmmm. I really want to try bull riding. Do you have any interest in that?\\n', \"Human 2: I'd love to try! Can we schedule something for next week?\\n\", 'Human 1: Sure! What does your Saturday look like?\\n', 'Human 2: Saturday looks pretty good, shall we shoot for something in the morning?\\n', 'Human 1: Hi!\\n', 'Human 2: hey\\n', 'Human 1: is it raining pretty bad today?\\n', 'Human 2: yeah, can walk too far to see all the foodtruck options\\n', \"Human 1: surprising that the rain started early this year... I don't like them too much. They make days gloomy\\n\", \"Human 2: yeah but I think it's good to have some rainy days in bay area, it's pretty dry here 😛\\n\", 'Human 1: Where I grew up, we had lots of water trouble too...\\n', \"Human 2: yeah like wise, I've seen a pretty bad snowstorm when I was at my undergrad school, all flights canceled and traffics went down\\n\", \"Human 1: Haha... I don't think I can survive in that weather ever. Just the rains at 50 degrees make me want to sit in heated rroms\\n\", 'Human 2: yeah how do you like it in bay area though? I think we need more rain here\\n', 'Human 1: people say there is drought here... but we have 24 hours water supply here ... lol... never seen that in a drought ridden area\\n', \"Human 2: it is pretty dry in the mountains I believe, that's what causes fire\\n\", 'Human 1: hmm.... okay. Climate change talk this morning was pretty darn interesting. did you see it?\\n', 'Human 2: nope, what does it say?\\n', 'Human 1: they were talking about how AI is helping climate change. Nice use of upcoming tech.\\n', 'Human 1: Hi.\\n', 'Human 2: Helloooooo!\\n', 'Human 1: How are you? How is your day?\\n', \"Human 2: Good. Don't have much to do today, feels good. How are you?\\n\", \"Human 1: I'm dressed very wel today so I feel good! I've been reading a lot about the psychology of positive outlook.\\n\", \"Human 2: So what's your outlook? Something blue?\\n\", \"Human 1: Yes. Blue is a tranquil colour. It's a good metaphor. Do you have good advice for positivity?\\n\", 'Human 2: You should drink more water, do some push up, and sleep early.\\n', 'Human 1: Hi!\\n', 'Human 2: Hey, how are you?\\n', \"Human 1: I'm a bit sad. I miss my cat.\\n\", 'Human 2: Oh no… Have you sent out the missing cat posters? Hope your cat is alright!\\n', \"Human 1: Posters is a great idea. So far I've just tried banging her catfood dish and shouting her name. Anyway, how is your day going so far?\\n\", 'Human 2: Yea, I know they love the plastic bag sound all the time. I am good, nothing special though.\\n', 'Human 1: If you could go anywhere on vacation, where would you go?\\n', 'Human 2: I like rainforest, but I know it requires extensive training beforehand.\\n', 'Human 1: I heard there are rainforests in southeast Asia where you can zipline from tree to tree.\\n', 'Human 2: I am afraid I will be scared of doing this :)\\n', \"Human 1: I won't lie, it sounds scary. I'm scared right now just thinking about it.\\n\", \"Human 2: I don't know if there is any medication for acrophobia. I want to take plenty of it if I really have to do it.\\n\", \"Human 1: If there isn't one, you should invent it, and then make millions\\n\", \"Human 2: That's a great idea! Maybe alcohol is such a thing.\\n\", \"Human 1: Ha! Don't drink and zipline, mate!\\n\", \"Human 2: Oops. I won't do it again. Ha\\n\", 'Human 1: Hi!\\n', 'Human 2: Hey sup\\n', 'Human 1: not much. any plans this weekend?\\n', \"Human 2: I'm going to try that thing where you hang from a wire as you go down. do you know what is it called?\\n\", 'Human 1: ziplining?\\n', \"Human 2: that's the one! have you ever tried it?\\n\", \"Human 1: i have a couple years ago. it's quite a unique experience\\n\", 'Human 2: where did you do it?\\n', \"Human 1: i forgot where it was, it wasn't local i don't think though\\n\", \"Human 2: no worries. what's the most exciting thing you ever done?\\n\", \"Human 1: that's a hard question and i'm tired so i'm going to go. see you\\n\", 'Human 2: sure. are you just going home now?\\n', \"Human 1: no, i'm going to get a massage first\\n\", 'Human 2: nice. what type?\\n', 'Human 1: traditional kind\\n', 'Human 2: yeah I want to get one too soon\\n', \"Human 1: you should! it's relaxing after a long day. talk to you later!\\n\", 'Human 2: ttyl!\\n', 'Human 1: Hi!\\n', 'Human 2: Hello, have you seen any good movies lately?\\n', \"Human 1: I watched a few lately, but nothing is as good as Avatar. what's your favorite?\\n\", 'Human 2: I have never seen Avatar, what is it about? I really enjoy the Avenger movies\\n', \"Human 1: it's a science-fiction movie with beautiful landscape of an imaginary nature with non-human creatures. people figured out a way to join that nature through Avatar transformation. the movie ends with a meaningful story of how human behaviors, e.g., cutting trees, have affected nature\\n\", 'Human 2: That sounds really cool! I think that movie did really well when it was in the box office so it must be good!\\n', 'Human 1: yea. what else do you like to do beside movies?\\n', 'Human 2: I enjoy baking cookies. I am on a quest to bake the best chocolate chip cookie 🙂 What about you?\\n', 'Human 1: I enjoy eating 🙂\\n', 'Human 2: so definitely would like to try your best chocolate cookie\\n', 'Human 1: I will have to bake some soon and let you know. What types of food do you like to eat?\\n', 'Human 2: thanks! I generally love noodle soups like Pho or Ramen :)\\n', 'Human 1: Noodle soup is delicious! Do you make homemade noodle soup or do you prefer to go out?\\n', \"Human 2: I prefer to go out. I'm not a good cook haha\\n\", 'Human 1: Same! Even though I bake, I cannot cook\\n', 'Human 2: seems like we share a thing in common, yay!\\n', 'Human 1: Hi!\\n', 'Human 2: Good afternoon!\\n', 'Human 1: How has your week been?\\n', 'Human 2: So far so good. It is holiday season. So just chilling\\n', \"Human 1: I think I'm getting sick with a cold 😞 So you should chill on my behalf too cause I'm out the game for all of December.\\n\", 'Human 2: lol Sorry to hear that. Are you planning anything fun for December?\\n', \"Human 1: Nothing exciting. I'll be posted up at home for the most part. I did a lot of travelling this year so my budget would have stopped me even if I wasn't sick.\\n\", 'Human 2: 😂\\n', 'Human 1: Do you have big plans?\\n', 'Human 2: Yes! I am going to Hawaii! This will be my first time visiting Hawaii. Really excited about it.\\n', \"Human 1: I love Hawaii. It's a good place to be. I like going there cause it's humid so I never have to put on lotion.\\n\", 'Human 2: lol this is the first time I heard from a boy who cares about humidity and lotion. I cannot agree more.\\n', \"Human 1: Brooooo!!! It's so important. When I got to California beaches I have to carry 3 litres of lotion for the whole day.\\n\", 'Human 2: 😂\\n', 'Human 1: Hi!\\n', \"Human 2: Oh hello. Long time no talk. How's the day going for yuo?\\n\", 'Human 1: Very well, thanks for asking. How has your day been?\\n', 'Human 2: Getting better. I just recovered from a cold. I got wet in the rain last week. Are you planning anything for the holidays?\\n', \"Human 1: Glad to hear you're better. Sorry to hear you were sick. I was sick a couple of weeks ago with a bad cough. There's definitely a bug going around. Admit I just want to stay healthy for the holidays and plan to relax.\\n\", 'Human 2: Oh same here. I think relaxing at home should be counted among the best ways to enjoy the holidays.\\n', \"Human 1: Definitely! I know a lot of folks travel for the holidays, but I'm happy to stay home myself!\\n\", \"Human 2: I'm getting there. Every year until last year, I tried to go somewhere for the Christmas / New Year, and then I got bored traveling. lol not sure if that means I'm getting old?\\n\", \"Human 1: Me too. Now I have folks come visit me for the holidays! But that's also tiresome..\\n\", 'Human 2: Are you doing any home decorating then?\\n', 'Human 1: Yes! We set up an eco-friendly (i.e. fake) Christmas tree and put up some colorful LED lights which is very festive.\\n', \"Human 2: I think I'm copying you. Me and my wife plan to decorate and Christmas tree too. We bought most of the decorative stuffs from the stores, but haven't yet to buy the tree.\\n\", 'Human 1: Buying a tree is a neat experience. I was torn between buying an artificial/eco-friendly/fake one vs. a real one that smells like fresh pine. In the end, we opted for the one that we can disassemble every year.\\n', 'Human 2: I see. Artificial anything is better, from tree to intelligence, huh?\\n', 'Human 1: Oh, very clever pun! I like it! Depends. I remember having real Christmas trees from childhood, but these days with climate change, I think not chopping down a tree just to decorate it and then throw it out in a month is the more responsible thing to do.\\n', \"Human 2: I see. It's probably also cheaper. I'll buy an artificial one too. Do you have any suggestions for the store?\\n\", 'Human 1: Admit my favorite store is Target, plus they often have good deals.\\n', \"Human 2: Ah that's great. My wife also likes Target a lot. She even made a Target credit card because she comes to that store very often. Okay thanks for the suggestion. I'll check out Target.\\n\", 'Human 1: Great, I hope you find a nice tree.\\n', 'Human 1: Hi!\\n', 'Human 2: Hey\\n', \"Human 1: How's your day going?\\n\", 'Human 2: pretty good. yours?\\n', \"Human 1: Ehh it's fine. I didn't do so well on that history test, actually..\\n\", 'Human 2: oh what happened?\\n', \"Human 1: Apparently Christopher Columbus didn't fight in the Civil War :')\\n\", 'Human 2: hahah wait for real?\\n', 'Human 1: I know right! Are you taking History next semester?\\n', \"Human 2: No I'm not in school anymore\\n\", 'Human 1: Oh I see. What do you do?\\n', 'Human 2: I train and compete in horse vaulting\\n', 'Human 1: Oh wow. Were you born a horse, or were you turned into one?\\n', \"Human 2: lol you're too funny\\n\", 'Human 1: Just kidding. That sounds pretty cool! Is it your job?\\n', 'Human 2: Yeah, but I part time work on a farm. Helping with a bit of everything\\n', 'Human 1: Wow, sounds very busy! Do you with money at those horse vaulting competitions?\\n', 'Human 2: Yeah some. enough to get by\\n', 'Human 1: Hi!\\n', 'Human 2: Hello\\n', 'Human 1: Do you have a favourite flower?\\n', \"Human 2: hmm, I haven't thought about that much, but i think lotus should be one of my favorites. Why do you ask?\\n\", \"Human 1: I'm working on a theory. Why does the lotus spring to mind?\\n\", 'Human 2: Nice! Lotus looks pretty cool and It has some delightful vibe. So what is this research about?\\n', \"Human 1: Oh, it's not research! Just a personal theory. I think that flower preferences are more revealing of personality than people appreciate.\\n\", 'Human 2: Interesting! Whats your favorite flower?\\n', 'Human 1: The gerbera. It\\'s like a cartoon flower. As if you drew \"flower\" with a crayon and then it came to life.\\n', 'Human 2: Nice, i would love know more about your theory. Like how you can deduce personality from flower preference.\\n', 'Human 1: Ok, step 1 is, you ask someone what their favourite flower is. Pretty much like what we just did. Does that make sense so far?\\n', 'Human 2: yes\\n', \"Human 1: Cool. Step 2: talk with the person some more, and ask them some more questions, and gradually develop a sense of what they're like, over the course of maybe two to five years. And voila\\n\", 'Human 2: Hehe, i think you should publish this someday :)\\n', \"Human 1: Why thank you, that's a wonderful idea!\\n\", 'Human 1: Hi!\\n', \"Human 2: Hey how's it going\\n\", \"Human 1: It's good it's good. How are you?\\n\", \"Human 2: good. it's really hot today. I think I'm going to the pool\\n\", 'Human 1: Oh nice! Where do you live?\\n', 'Human 2: I live in Tokyo, Japan\\n', 'Human 1: Ahh yes, Japan is hot during the summer. Last time I was in Kyoto it was 114 degrees....\\n', 'Human 2: oh have you been?\\n', \"Human 1: Yes yes. I've been to Tokyo as well. It's so nice!\\n\", 'Human 2: what did you do here?\\n', 'Human 1: Oh everything! I went to an onsen, the fish market, disney land and giant robot fighting show haha\\n', 'Human 2: lol why did you come to Japan just to go to Disney land?\\n', \"Human 1: The Disney lands are all different! There's also Disney Sea, which is completely unique!\\n\", \"Human 2: oh neat. I haven't heard about that robot fighting show. where is that??\\n\", 'Human 1: I don\\'t really remember what part of town it was in. It was pretty cool though - I\\'m sure you can find it if you google \"giant robot fighting show tokyo\" haha\\n', 'Human 2: lol ok\\n', 'Human 1: Hi!\\n', 'Human 2: Have you seen any good movies lately?\\n', 'Human 1: Last weekend I saw \"The Parasite.\" Ever heard of it?\\n', 'Human 2: No. Why did you pick that movie?\\n', 'Human 1: My friend wanted to see it. It has great reviews on IMDB and Rotten Tomatoes! What did you do last weekend?\\n', 'Human 2: I played music and worked on some side projects. I also started watching the new Disney service.\\n', 'Human 1: Oooo the Mandalorian?!?!\\n', 'Human 2: Mostly, the deleted scenes from Avengers.. lol\\n', 'Human 1: lol Are you a big Marvel fan?\\n', 'Human 2: I loved the X-Men as a kid, and even collected the comic cards. Recently, I got very into the Marvel Cinematic Universe movies. How many Avengers movies have you seen?\\n', \"Human 1: I've only seen Spiderman. Honestly it was a little too scary and so I don't think I can bring myself to watch the other Marvel movies! haha\\n\", 'Human 2: Oh!-- I have a friend who looks like the actor who plays Spiderman.\\n', 'Human 1: Oh really? To be honest I think the actor is not that good looking, so not so surprising! haha\\n', 'Human 2: Yea. I think Loki is the most handsome 😀\\n', \"Human 1: Who is Loki? I've never heard that name before\\n\", \"Human 2: He's the adopted brother of Thor, God of thunder, and is burdened with glorious purpose. Do you feel that burden?\\n\", 'Human 1: Hi!\\n', \"Human 2: Hey, what's up?\\n\", \"Human 1: Just chillin'. how are you?\\n\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5i6LvjlH2K1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now we will build our corpus of questions and answers\n",
        "question,answer=[],[]\n",
        "#here we will assume human1 query as question, human2 query as answer\n",
        "for each in text:\n",
        "  if 'Human 1' in each or '':\n",
        "    question.append(each[9:-1])\n",
        "  else:\n",
        "    answer.append(each[9:-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE3h_HxaJMqf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f8277db1-c32b-43aa-917c-84ae4deed60f"
      },
      "source": [
        "for i in range(2):\n",
        "  print('Question : ',question[i])\n",
        "  print('Answer : ',answer[i])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question :  Hi!\n",
            "Answer :  What is your favorite holiday?\n",
            "Question :  one where I get to meet lots of different people.\n",
            "Answer :  What was the most number of people you have ever met during a holiday?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8gPEgN4JboF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build tokenizer using tfds for both questions and answers\n",
        "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    question + answer, target_vocab_size=2**13)\n",
        "\n",
        "# Define start and end token to indicate the start and end of a sentence\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# Vocabulary size plus start and end token\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnd5Q2pDJ4qZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86a8c30d-4860-4a65-afd2-31040284eca1"
      },
      "source": [
        "print('Tokenized sample question: {}'.format(tokenizer.encode(question[20])))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized sample question: [3817, 93, 709, 2632, 8, 138, 289, 12, 68, 3274, 1, 2, 18, 2109, 3, 27, 417, 2, 464, 2, 91, 82, 56, 15, 1510, 3923]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3jr0h-aJ-C-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Maximum sentence length\n",
        "MAX_LENGTH = 40\n",
        "\n",
        "\n",
        "# Tokenize, filter and pad sentences\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "  \n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # tokenize sentence\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "    # check tokenized sentence max length\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "  \n",
        "  # pad tokenized sentences\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  \n",
        "  return tokenized_inputs, tokenized_outputs\n",
        "\n",
        "\n",
        "question, answer = tokenize_and_filter(question, answer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOW_2IefKH9v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0e5cb6dd-6594-4939-d298-90bd34426a84"
      },
      "source": [
        "print('Vocab size: {}'.format(VOCAB_SIZE))\n",
        "print('Number of samples: {}'.format(len(question)))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 4148\n",
            "Number of samples: 658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5Qc8CaDKNGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# decoder inputs use the previous target as input\n",
        "# remove START_TOKEN from targets\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': question,\n",
        "        'dec_inputs': answer[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answer[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGJaUlKaKaZ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1f4592e-f7cf-47a3-8675-30a7364ee13f"
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: ({inputs: (None, 40), dec_inputs: (None, 39)}, {outputs: (None, 39)}), types: ({inputs: tf.int32, dec_inputs: tf.int32}, {outputs: tf.int32})>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qia8VGgfKeLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  \"\"\"Calculate the attention weights. \"\"\"\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask to zero out padding tokens\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmwXPOj4KjSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # final linear layer\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUfbx65eKmVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed7K3NqIKoOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQWBrFwPKxWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQVNYoM7K38u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lSzaOrgLGlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUyroIePLH_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_encoder = encoder(\n",
        "    vocab_size=8192,\n",
        "    num_layers=2,\n",
        "    units=512,\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    dropout=0.3,\n",
        "    name=\"sample_encoder\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX0O_T8JLL48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "539XsR5_LRDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_decoder_layer = decoder_layer(\n",
        "    units=512,\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    dropout=0.3,\n",
        "    name=\"sample_decoder_layer\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOm3DS3GLWRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFYyY-zNLY7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_decoder = decoder(\n",
        "    vocab_size=8192,\n",
        "    num_layers=2,\n",
        "    units=512,\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    dropout=0.3,\n",
        "    name=\"sample_decoder\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fXvVtHFLcl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "  # mask the future tokens for decoder inputs at the 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "  # mask the encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TxA_nQ-LfC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_transformer = transformer(\n",
        "    vocab_size=8192,\n",
        "    num_layers=4,\n",
        "    units=512,\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    dropout=0.3,\n",
        "    name=\"sample_transformer\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlTlxtRALh-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xibiDuIGLi60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_3ki-ZRLyDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zVvvAv-LrBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjcygvvoL0aO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d4b5a701-cd18-410f-ae45-575d3d0a8818"
      },
      "source": [
        "EPOCHS = 150\n",
        "\n",
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 11 steps\n",
            "Epoch 1/150\n",
            "11/11 [==============================] - 7s 678ms/step - loss: 3.3275 - accuracy: 0.0000e+00\n",
            "Epoch 2/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 3.3000 - accuracy: 3.8968e-05\n",
            "Epoch 3/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 3.3290 - accuracy: 0.0000e+00\n",
            "Epoch 4/150\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 3.2383 - accuracy: 8.1833e-04\n",
            "Epoch 5/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 3.2444 - accuracy: 0.0132\n",
            "Epoch 6/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 3.1558 - accuracy: 0.0245\n",
            "Epoch 7/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 3.1297 - accuracy: 0.0256\n",
            "Epoch 8/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 3.0975 - accuracy: 0.0256\n",
            "Epoch 9/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 3.0937 - accuracy: 0.0256\n",
            "Epoch 10/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 3.0030 - accuracy: 0.0256\n",
            "Epoch 11/150\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 3.0105 - accuracy: 0.0256\n",
            "Epoch 12/150\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 2.9707 - accuracy: 0.0256\n",
            "Epoch 13/150\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 2.9611 - accuracy: 0.0256\n",
            "Epoch 14/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 2.9013 - accuracy: 0.0256\n",
            "Epoch 15/150\n",
            "11/11 [==============================] - 1s 72ms/step - loss: 2.7998 - accuracy: 0.0256\n",
            "Epoch 16/150\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 2.8027 - accuracy: 0.0256\n",
            "Epoch 17/150\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 2.7991 - accuracy: 0.0256\n",
            "Epoch 18/150\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 2.7115 - accuracy: 0.0256\n",
            "Epoch 19/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 2.6991 - accuracy: 0.0256\n",
            "Epoch 20/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 2.6375 - accuracy: 0.0256\n",
            "Epoch 21/150\n",
            "11/11 [==============================] - 1s 72ms/step - loss: 2.6109 - accuracy: 0.0257\n",
            "Epoch 22/150\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 2.5526 - accuracy: 0.0272\n",
            "Epoch 23/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 2.5356 - accuracy: 0.0289\n",
            "Epoch 24/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 2.5136 - accuracy: 0.0303\n",
            "Epoch 25/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 2.4407 - accuracy: 0.0319\n",
            "Epoch 26/150\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 2.4440 - accuracy: 0.0336\n",
            "Epoch 27/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 2.4088 - accuracy: 0.0372\n",
            "Epoch 28/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 2.4108 - accuracy: 0.0406\n",
            "Epoch 29/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 2.3918 - accuracy: 0.0429\n",
            "Epoch 30/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 2.3238 - accuracy: 0.0492\n",
            "Epoch 31/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 2.2668 - accuracy: 0.0524\n",
            "Epoch 32/150\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 2.2909 - accuracy: 0.0570\n",
            "Epoch 33/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 2.2638 - accuracy: 0.0630\n",
            "Epoch 34/150\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 2.1965 - accuracy: 0.0664\n",
            "Epoch 35/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 2.1590 - accuracy: 0.0709\n",
            "Epoch 36/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 2.1729 - accuracy: 0.0761\n",
            "Epoch 37/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 2.1132 - accuracy: 0.0793\n",
            "Epoch 38/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 2.0467 - accuracy: 0.0827\n",
            "Epoch 39/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 2.0572 - accuracy: 0.0849\n",
            "Epoch 40/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 2.0079 - accuracy: 0.0892\n",
            "Epoch 41/150\n",
            "11/11 [==============================] - 1s 73ms/step - loss: 1.9551 - accuracy: 0.0922\n",
            "Epoch 42/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 1.9364 - accuracy: 0.0943\n",
            "Epoch 43/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 1.9228 - accuracy: 0.0987\n",
            "Epoch 44/150\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 1.8764 - accuracy: 0.1014\n",
            "Epoch 45/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 1.8382 - accuracy: 0.1047\n",
            "Epoch 46/150\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 1.8238 - accuracy: 0.1086\n",
            "Epoch 47/150\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 1.7599 - accuracy: 0.1121\n",
            "Epoch 48/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 1.7523 - accuracy: 0.1164\n",
            "Epoch 49/150\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 1.7044 - accuracy: 0.1199\n",
            "Epoch 50/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 1.6627 - accuracy: 0.1229\n",
            "Epoch 51/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 1.6453 - accuracy: 0.1252\n",
            "Epoch 52/150\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 1.6341 - accuracy: 0.1308\n",
            "Epoch 53/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 1.5991 - accuracy: 0.1333\n",
            "Epoch 54/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 1.5460 - accuracy: 0.1349\n",
            "Epoch 55/150\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 1.5155 - accuracy: 0.1390\n",
            "Epoch 56/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 1.4808 - accuracy: 0.1427\n",
            "Epoch 57/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 1.4761 - accuracy: 0.1451\n",
            "Epoch 58/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 1.4402 - accuracy: 0.1482\n",
            "Epoch 59/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 1.4080 - accuracy: 0.1513\n",
            "Epoch 60/150\n",
            "11/11 [==============================] - 1s 73ms/step - loss: 1.3839 - accuracy: 0.1545\n",
            "Epoch 61/150\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 1.3628 - accuracy: 0.1580\n",
            "Epoch 62/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 1.3133 - accuracy: 0.1617\n",
            "Epoch 63/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 1.2967 - accuracy: 0.1660\n",
            "Epoch 64/150\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 1.2810 - accuracy: 0.1707\n",
            "Epoch 65/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 1.2409 - accuracy: 0.1748\n",
            "Epoch 66/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 1.2001 - accuracy: 0.1799\n",
            "Epoch 67/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 1.1754 - accuracy: 0.1831\n",
            "Epoch 68/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 1.1505 - accuracy: 0.1851\n",
            "Epoch 69/150\n",
            "11/11 [==============================] - 1s 72ms/step - loss: 1.1509 - accuracy: 0.1909\n",
            "Epoch 70/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 1.1058 - accuracy: 0.1967\n",
            "Epoch 71/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 1.0795 - accuracy: 0.1984\n",
            "Epoch 72/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 1.0462 - accuracy: 0.2039\n",
            "Epoch 73/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 1.0258 - accuracy: 0.2092\n",
            "Epoch 74/150\n",
            "11/11 [==============================] - 1s 72ms/step - loss: 0.9936 - accuracy: 0.2136\n",
            "Epoch 75/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 0.9699 - accuracy: 0.2205\n",
            "Epoch 76/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 0.9349 - accuracy: 0.2221\n",
            "Epoch 77/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 0.9289 - accuracy: 0.2292\n",
            "Epoch 78/150\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 0.8877 - accuracy: 0.2332\n",
            "Epoch 79/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 0.8550 - accuracy: 0.2406\n",
            "Epoch 80/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 0.8430 - accuracy: 0.2434\n",
            "Epoch 81/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 0.8205 - accuracy: 0.2496\n",
            "Epoch 82/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 0.7803 - accuracy: 0.2556\n",
            "Epoch 83/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 0.7508 - accuracy: 0.2594\n",
            "Epoch 84/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 0.7393 - accuracy: 0.2664\n",
            "Epoch 85/150\n",
            "11/11 [==============================] - 1s 73ms/step - loss: 0.7074 - accuracy: 0.2708\n",
            "Epoch 86/150\n",
            "11/11 [==============================] - 1s 73ms/step - loss: 0.6778 - accuracy: 0.2793\n",
            "Epoch 87/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 0.6648 - accuracy: 0.2847\n",
            "Epoch 88/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 0.6338 - accuracy: 0.2897\n",
            "Epoch 89/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 0.6048 - accuracy: 0.2971\n",
            "Epoch 90/150\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 0.5858 - accuracy: 0.3042\n",
            "Epoch 91/150\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 0.5603 - accuracy: 0.3080\n",
            "Epoch 92/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 0.5381 - accuracy: 0.3136\n",
            "Epoch 93/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 0.5049 - accuracy: 0.3204\n",
            "Epoch 94/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 0.4805 - accuracy: 0.3281\n",
            "Epoch 95/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 0.4543 - accuracy: 0.3329\n",
            "Epoch 96/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 0.4370 - accuracy: 0.3395\n",
            "Epoch 97/150\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 0.4109 - accuracy: 0.3434\n",
            "Epoch 98/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 0.3901 - accuracy: 0.3491\n",
            "Epoch 99/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 0.3715 - accuracy: 0.3514\n",
            "Epoch 100/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 0.3519 - accuracy: 0.3570\n",
            "Epoch 101/150\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 0.3322 - accuracy: 0.3620\n",
            "Epoch 102/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 0.3104 - accuracy: 0.3675\n",
            "Epoch 103/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 0.2894 - accuracy: 0.3710\n",
            "Epoch 104/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 0.2717 - accuracy: 0.3738\n",
            "Epoch 105/150\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 0.2493 - accuracy: 0.3764\n",
            "Epoch 106/150\n",
            "11/11 [==============================] - 1s 73ms/step - loss: 0.2343 - accuracy: 0.3783\n",
            "Epoch 107/150\n",
            "11/11 [==============================] - 1s 72ms/step - loss: 0.2161 - accuracy: 0.3805\n",
            "Epoch 108/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 0.2014 - accuracy: 0.3827\n",
            "Epoch 109/150\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 0.1896 - accuracy: 0.3838\n",
            "Epoch 110/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 0.1733 - accuracy: 0.3852\n",
            "Epoch 111/150\n",
            "11/11 [==============================] - 1s 73ms/step - loss: 0.1605 - accuracy: 0.3859\n",
            "Epoch 112/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 0.1501 - accuracy: 0.3874\n",
            "Epoch 113/150\n",
            "11/11 [==============================] - 1s 73ms/step - loss: 0.1378 - accuracy: 0.3879\n",
            "Epoch 114/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 0.1276 - accuracy: 0.3887\n",
            "Epoch 115/150\n",
            "11/11 [==============================] - 1s 71ms/step - loss: 0.1163 - accuracy: 0.3891\n",
            "Epoch 116/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 0.1112 - accuracy: 0.3899\n",
            "Epoch 117/150\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 0.1070 - accuracy: 0.3896\n",
            "Epoch 118/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 0.0956 - accuracy: 0.3901\n",
            "Epoch 119/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 0.0886 - accuracy: 0.3900\n",
            "Epoch 120/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 0.0820 - accuracy: 0.3905\n",
            "Epoch 121/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 0.0773 - accuracy: 0.3906\n",
            "Epoch 122/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 0.0705 - accuracy: 0.3908\n",
            "Epoch 123/150\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 0.0670 - accuracy: 0.3910\n",
            "Epoch 124/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 0.0624 - accuracy: 0.3910\n",
            "Epoch 125/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 0.0600 - accuracy: 0.3912\n",
            "Epoch 126/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 0.0564 - accuracy: 0.3914\n",
            "Epoch 127/150\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 0.0527 - accuracy: 0.3911\n",
            "Epoch 128/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 0.0489 - accuracy: 0.3915\n",
            "Epoch 129/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 0.0474 - accuracy: 0.3912\n",
            "Epoch 130/150\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.0437 - accuracy: 0.3916\n",
            "Epoch 131/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 0.0421 - accuracy: 0.3912\n",
            "Epoch 132/150\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 0.0413 - accuracy: 0.3908\n",
            "Epoch 133/150\n",
            "11/11 [==============================] - 1s 73ms/step - loss: 0.0364 - accuracy: 0.3916\n",
            "Epoch 134/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 0.0357 - accuracy: 0.3914\n",
            "Epoch 135/150\n",
            "11/11 [==============================] - 1s 73ms/step - loss: 0.0346 - accuracy: 0.3916\n",
            "Epoch 136/150\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 0.0324 - accuracy: 0.3916\n",
            "Epoch 137/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 0.0320 - accuracy: 0.3917\n",
            "Epoch 138/150\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 0.0317 - accuracy: 0.3914\n",
            "Epoch 139/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 0.0309 - accuracy: 0.3914\n",
            "Epoch 140/150\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 0.0305 - accuracy: 0.3917\n",
            "Epoch 141/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 0.0292 - accuracy: 0.3914\n",
            "Epoch 142/150\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 0.0286 - accuracy: 0.3914\n",
            "Epoch 143/150\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.0257 - accuracy: 0.3919\n",
            "Epoch 144/150\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 0.0253 - accuracy: 0.3918\n",
            "Epoch 145/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 0.0247 - accuracy: 0.3917\n",
            "Epoch 146/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 0.0242 - accuracy: 0.3916\n",
            "Epoch 147/150\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 0.0255 - accuracy: 0.3916\n",
            "Epoch 148/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 0.0241 - accuracy: 0.3915\n",
            "Epoch 149/150\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 0.0246 - accuracy: 0.3916\n",
            "Epoch 150/150\n",
            "11/11 [==============================] - 1s 73ms/step - loss: 0.0241 - accuracy: 0.3916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1d300f3c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVDL01KBMkzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  sentence = sentence.lower().strip()\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  # adding a start and an end token to the sentence\n",
        "  return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs0ZYpaDMOeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cYyBdSjMQ_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5b9f1365-833c-40c4-dd0b-a3d2b8b3a0eb"
      },
      "source": [
        "output = predict('Who are you?')"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: Who are you?\n",
            "Output: I think it's like a bit sad and slow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dfAGvZ_TEMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fe64ab03-35c5-4f34-ea45-28dea13eb9d9"
      },
      "source": [
        "output=predict('hello')"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: hello\n",
            "Output: I trained in contemporary and jazz, so I can pick up work in commercials and film clips in between stage shows. So it ends up being all sorts of styles.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i1erbxwTJ-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "07d15c52-c844-4aaa-e6b7-b9305e7ba2f5"
      },
      "source": [
        "output=predict('Nice to meet you!')"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: Nice to meet you!\n",
            "Output: I trained in contemporary and jazz, so I can pick up work in commercials and film clips in between stage shows. So it ends up being all sorts of styles.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COhwuhZHTQgt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "63c59397-c95a-4fbd-9a3d-17c78bd4afac"
      },
      "source": [
        "output=predict ('Did you visit America?')"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: Did you visit America?\n",
            "Output: Cool! Do you watch Game of Thrones?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ueZWgWSTijm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5511bc24-a35a-4fa5-aced-2bdfadc95207"
      },
      "source": [
        "output=predict ('Nice!')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: Nice!\n",
            "Output: yeah. I studied English there for a while. Awesome experience\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxH5v8woTnjz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f4af5576-90ab-4d49-c13b-990516ed11ca"
      },
      "source": [
        "output=predict('Speak to me in English')"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: Speak to me in English\n",
            "Output: Oh same here. I think relaxing at home should be counted among the best ways to enjoy the holidays.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47r_9k_ZTs1Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2c0bda06-5508-4580-98ce-45bb21826f7b"
      },
      "source": [
        "output=predict('Out for holidays?')"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: Out for holidays?\n",
            "Output: Hello!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTaLrBtTTxZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f98787e2-893f-4f06-f37b-17c3a0bd882c"
      },
      "source": [
        "output=predict('You are a liar.')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: You are a liar.\n",
            "Output: Which holiday was that. Is it requires a bunch of turkey\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WnQQXApT2we",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f67a3718-dcee-447f-a6d7-e58461e0f7ad"
      },
      "source": [
        "output=predict('Tell me a joke.')"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: Tell me a joke.\n",
            "Output: can't wait to try your food. why not cook this Thanksgiving? 🙂\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}